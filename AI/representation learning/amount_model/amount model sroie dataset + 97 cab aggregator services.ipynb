{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "967e0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "vocab_file='./amount_vocab.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b4a7bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Decode and convert to grayscale\n",
    "    img = cv2.imdecode(np.frombuffer(img, np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    # Denoising Image\n",
    "    img = cv2.fastNlMeansDenoising( img, None, 15, 7, 21 )   \n",
    "    # Image Binarization\n",
    "    img=cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    # Perform morphological operations (erosion and dilation)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    return cv2.morphologyEx(img, cv2.MORPH_DILATE, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9d0541eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=json.load(open(vocab_file,'r+'))\n",
    "def words_to_id(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    if re.fullmatch(r\"[0-9]*\\.?[0-9]+\", text):\n",
    "        return vocab[\"number\"]\n",
    "    if text in vocab:\n",
    "        return vocab[text] \n",
    "    return vocab[\"rare\"]  #rare means the words that does not exist in vocabulary     \n",
    "\n",
    "\n",
    "def detect_candidate(text):\n",
    "  if pd.isna(text):\n",
    "     return None\n",
    "  if re.fullmatch(r\"[0-9]*\\.?[0-9]+\",text): \n",
    "      return 1  # amount type = 1\n",
    "  return None\n",
    "\n",
    "def preprocess(text):\n",
    "    if pd.isna(text) or text=='':\n",
    "        return None\n",
    "    text=str(text)\n",
    "    #remove punctuation mark from the text\n",
    "    text=text.translate(str.maketrans('','',''',!\"#%&'()*+-/:;<=>?@[\\]^_`{|}~â‚¹$'''))\n",
    "    # lower case each letter of the word\n",
    "    text=text.lower()\n",
    "    if re.fullmatch(r\"rm\\s*[0-9]*\\.?[0-9]+\",text):\n",
    "        text=re.sub(r'[^\\d\\.]','',text)\n",
    "    return text\n",
    "\n",
    "# check if amount is the total amount of invoice or not with the help of json labels. \n",
    "def check_correctness(text,amount):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    if re.fullmatch(r\"[0-9]*\\.?[0-9]+\", text):\n",
    "        if float(text) ==float(amount):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Form candidates dataframe which contains features of it's position and neighbour words.\n",
    "def get_candidates(df,correct_amount):\n",
    "    cand=pd.DataFrame(columns=['field_id','candidate_position','neighbour_id','neighbour_relative_position','correct_candidate','left','top','width','height','text'])\n",
    "    cand['left']=df['left']\n",
    "    cand['top']=df['top']\n",
    "    cand['width']=df['width']\n",
    "    cand['height']=df['height']\n",
    "    cand['field_id']=df['text'].apply(detect_candidate)\n",
    "    cand['text']=df['text']\n",
    "    cand['correct_candidate']=df['text'].apply(check_correctness,amount=correct_amount)\n",
    "    cand.dropna(subset=['field_id','top','width','height','left','text'],inplace=True)\n",
    "    return cand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "50f98e81",
   "metadata": {},
   "outputs": [],
   "source": [
    " def generate(df,num_neighbours,correct_amount,height,width):\n",
    "        df['text']=df['text'].apply(preprocess)   #preprocess all the words \n",
    "        candidates_df=get_candidates(df,correct_amount)\n",
    "        df['text']=df['text'].apply(words_to_id)\n",
    "        df.dropna(subset=['text'],inplace=True)\n",
    "        \n",
    "        #Example: for each number get it's closest neighbour words with their positional features for model training  \n",
    "        for i,cand_row in candidates_df.iterrows():               \n",
    "            neighbour=dict()\n",
    "            x1=(cand_row['left']+cand_row['width']/2)/width\n",
    "            y1=(cand_row['top']+cand_row['height']/2)/height\n",
    "            for j,neigh_row in df.iterrows():\n",
    "                id=neigh_row['text'] # earlier each word was converted to it's numerical value , so used here \n",
    "                # positions of words need to be normalized \n",
    "                # there centroid coordinate is taken in consideration\n",
    "                if id==vocab[\"number\"]:\n",
    "                    continue\n",
    "                x2=(neigh_row['left']+neigh_row['width']/2)/width\n",
    "                y2=(neigh_row['top']+neigh_row['height']/2)/height\n",
    "                #Ex. neighbours are searched towards left and half page upwards to the amount\n",
    "                if x2 > x1 or y2 > y1+0.02 or y2 < y1-0.1:\n",
    "                    continue\n",
    "                distance=math.dist([x1,y1],[x2,y2])\n",
    "                if id in neighbour:\n",
    "                    if distance<neighbour[id]['dist']:\n",
    "                        neighbour[id]={\n",
    "                            'dist':distance,\n",
    "                            'left':x2,'top':y2\n",
    "                        }\n",
    "                else:\n",
    "                    neighbour[id]={\n",
    "                        'dist':distance,\n",
    "                        'left':x2,'top':y2\n",
    "                    }     \n",
    "            # if an entity has no neighbours, then there is no point to train it so continue .\n",
    "            if len(neighbour)==0:\n",
    "                continue\n",
    "            # sort to form n closest neighbours\n",
    "            neighbour=dict(sorted(neighbour.items(), key=lambda item: item[1]['dist'])[:num_neighbours])\n",
    "            neighbours_remaining=num_neighbours-len(neighbour)\n",
    "            neighbour_positions=list()\n",
    "            neighbour_id=list()\n",
    "            num_valid_values=0\n",
    "            for key in neighbour:\n",
    "                if key!=vocab['rare']: \n",
    "                   num_valid_values+=1 \n",
    "                neighbour_id.append(key)\n",
    "                neighbour_positions.append([neighbour[key]['left']-x1,neighbour[key]['top']-x2])\n",
    "            \n",
    "            # if a number is true amount and it does not has valid neighbours then do not take it into consideration for training\n",
    "            if candidates_df.at[i,'correct_candidate']==True and num_valid_values==0:\n",
    "                continue\n",
    "            # To make the data consistent , like if 10 neighbours are needed and only 4 neighbours are present then other values\n",
    "            # need to be padded with zero's to feed machine learning model.\n",
    "            while neighbours_remaining: #used for masking\n",
    "                neighbour_id.append(0)  \n",
    "                neighbour_positions.append([-1,-1]) \n",
    "                neighbours_remaining-=1\n",
    "    \n",
    "            candidates_df.at[i,'neighbour_id']=neighbour_id\n",
    "            candidates_df.at[i,'neighbour_relative_position']=neighbour_positions\n",
    "            candidates_df.at[i,'candidate_position']=list([float(x1),float(y1)]) \n",
    "            \n",
    "        # remove the invalid rows from the dataframe , the invalid rows has undefined values . \n",
    "        candidates_df.dropna(subset=['field_id','candidate_position','neighbour_id','neighbour_relative_position','left','top','width','height'],inplace=True)\n",
    "        return candidates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "118f9f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(csv_dataset,key,num_neighbours):\n",
    "        candidates=None\n",
    "        invoices=os.listdir(csv_dataset)\n",
    "        length=len(invoices)\n",
    "        for inv_csv in range(0,length): \n",
    "           file_name=str(inv_csv)\n",
    "           file_name=file_name.zfill(3)\n",
    "           data=json.load(open(key+'/'+file_name+'.json','r'))\n",
    "           if 'amount' in data:\n",
    "               total=str(data['amount'])\n",
    "           else:\n",
    "               total=str(data['total'])\n",
    "           if total=='':\n",
    "              continue\n",
    "           total=preprocess(total)\n",
    "           df=pd.read_csv(f'{csv_dataset}/{file_name}.csv')\n",
    "           height=max(df['top'].max(),df['height'].max())\n",
    "           width=max(df['left'].max(),df['width'].max())\n",
    "           df=generate(df,num_neighbours,total,height,width)\n",
    "           if type(candidates)!=None :\n",
    "             if not df.empty:\n",
    "                candidates=pd.concat([candidates,df])\n",
    "                if len(candidates[candidates['correct_candidate']==True])==0:\n",
    "                    print('incorrect')\n",
    "             else:\n",
    "                print('a empty dataframe for file',inv_csv)\n",
    "           else:\n",
    "             candidates=df  \n",
    "        candidates.reset_index(inplace=True) \n",
    "        return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "db010cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a empty dataframe for file 249\n",
      "a empty dataframe for file 413\n"
     ]
    }
   ],
   "source": [
    "key='./json_keys'\n",
    "csv_dataset='./tesseract_invoice_csv_dataset'\n",
    "dataset=generate_dataset(csv_dataset,key,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "967b8aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total candidates:  17088\n",
      "positive candidates:  913\n"
     ]
    }
   ],
   "source": [
    "print('total candidates: ',len(dataset))\n",
    "print('positive candidates: ',len(dataset[dataset['correct_candidate']==True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "714b6a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from functional_train import Model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8c37e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=28\n",
    "EMBEDDING_SIZE=100\n",
    "NEIGHBOURS=10\n",
    "HEADS=4\n",
    "df=dataset\n",
    "y_train=tf.convert_to_tensor(list(df['correct_candidate']))\n",
    "cand_pos=tf.convert_to_tensor(list(df['candidate_position']))\n",
    "neighbours=tf.convert_to_tensor(list(df['neighbour_id']))\n",
    "neighbour_positions=tf.convert_to_tensor(list(df['neighbour_relative_position']))\n",
    "field_id=tf.convert_to_tensor(list(df['field_id']))\n",
    "model = Model(VOCAB_SIZE, EMBEDDING_SIZE, NEIGHBOURS, HEADS)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(0.0001),\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.AUC(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "af877501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "534/534 [==============================] - 17s 28ms/step - loss: 0.1788 - accuracy: 0.1554 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - auc_8: 0.8235\n",
      "Epoch 2/150\n",
      "534/534 [==============================] - 14s 26ms/step - loss: 0.1437 - accuracy: 0.2154 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - auc_8: 0.9014\n",
      "Epoch 3/150\n",
      "534/534 [==============================] - 14s 26ms/step - loss: 0.1395 - accuracy: 0.2022 - precision_8: 1.0000 - recall_8: 0.0011 - auc_8: 0.9093\n",
      "Epoch 4/150\n",
      "534/534 [==============================] - 14s 26ms/step - loss: 0.1375 - accuracy: 0.1835 - precision_8: 0.6000 - recall_8: 0.0066 - auc_8: 0.9130\n",
      "Epoch 5/150\n",
      "534/534 [==============================] - 14s 26ms/step - loss: 0.1358 - accuracy: 0.1985 - precision_8: 0.4815 - recall_8: 0.0142 - auc_8: 0.9153\n",
      "Epoch 6/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1339 - accuracy: 0.2228 - precision_8: 0.6176 - recall_8: 0.0230 - auc_8: 0.9194\n",
      "Epoch 7/150\n",
      "534/534 [==============================] - 14s 26ms/step - loss: 0.1345 - accuracy: 0.2210 - precision_8: 0.4889 - recall_8: 0.0241 - auc_8: 0.9185\n",
      "Epoch 8/150\n",
      "534/534 [==============================] - 14s 27ms/step - loss: 0.1318 - accuracy: 0.2135 - precision_8: 0.5287 - recall_8: 0.0504 - auc_8: 0.9233\n",
      "Epoch 9/150\n",
      "534/534 [==============================] - 14s 27ms/step - loss: 0.1306 - accuracy: 0.2228 - precision_8: 0.5391 - recall_8: 0.0679 - auc_8: 0.9252\n",
      "Epoch 10/150\n",
      "534/534 [==============================] - 14s 27ms/step - loss: 0.1294 - accuracy: 0.2453 - precision_8: 0.5323 - recall_8: 0.0723 - auc_8: 0.9271\n",
      "Epoch 11/150\n",
      "534/534 [==============================] - 15s 27ms/step - loss: 0.1294 - accuracy: 0.2022 - precision_8: 0.4857 - recall_8: 0.0745 - auc_8: 0.9281\n",
      "Epoch 12/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1283 - accuracy: 0.2678 - precision_8: 0.5529 - recall_8: 0.1030 - auc_8: 0.9285\n",
      "Epoch 13/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1276 - accuracy: 0.2753 - precision_8: 0.5868 - recall_8: 0.1073 - auc_8: 0.9299\n",
      "Epoch 14/150\n",
      "534/534 [==============================] - 15s 27ms/step - loss: 0.1262 - accuracy: 0.2509 - precision_8: 0.5366 - recall_8: 0.1205 - auc_8: 0.9322\n",
      "Epoch 15/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1252 - accuracy: 0.2397 - precision_8: 0.5973 - recall_8: 0.1446 - auc_8: 0.9335\n",
      "Epoch 16/150\n",
      "534/534 [==============================] - 15s 27ms/step - loss: 0.1252 - accuracy: 0.2509 - precision_8: 0.6063 - recall_8: 0.1468 - auc_8: 0.9326\n",
      "Epoch 17/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1247 - accuracy: 0.2491 - precision_8: 0.5444 - recall_8: 0.1479 - auc_8: 0.9332\n",
      "Epoch 18/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1238 - accuracy: 0.2659 - precision_8: 0.5628 - recall_8: 0.1522 - auc_8: 0.9350\n",
      "Epoch 19/150\n",
      "534/534 [==============================] - 15s 27ms/step - loss: 0.1227 - accuracy: 0.2378 - precision_8: 0.6226 - recall_8: 0.1752 - auc_8: 0.9349\n",
      "Epoch 20/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1220 - accuracy: 0.2360 - precision_8: 0.6468 - recall_8: 0.1906 - auc_8: 0.9363\n",
      "Epoch 21/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1213 - accuracy: 0.3090 - precision_8: 0.6037 - recall_8: 0.1785 - auc_8: 0.9383\n",
      "Epoch 22/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1201 - accuracy: 0.2846 - precision_8: 0.6245 - recall_8: 0.1676 - auc_8: 0.9393\n",
      "Epoch 23/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.1194 - accuracy: 0.2772 - precision_8: 0.6237 - recall_8: 0.1906 - auc_8: 0.9397\n",
      "Epoch 24/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1196 - accuracy: 0.3090 - precision_8: 0.6286 - recall_8: 0.1928 - auc_8: 0.9396\n",
      "Epoch 25/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1178 - accuracy: 0.3427 - precision_8: 0.6431 - recall_8: 0.2092 - auc_8: 0.9422\n",
      "Epoch 26/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1183 - accuracy: 0.2903 - precision_8: 0.6295 - recall_8: 0.2103 - auc_8: 0.9413\n",
      "Epoch 27/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1182 - accuracy: 0.2547 - precision_8: 0.6312 - recall_8: 0.2081 - auc_8: 0.9418\n",
      "Epoch 28/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1172 - accuracy: 0.3296 - precision_8: 0.6429 - recall_8: 0.2169 - auc_8: 0.9423\n",
      "Epoch 29/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1157 - accuracy: 0.2959 - precision_8: 0.6465 - recall_8: 0.2344 - auc_8: 0.9446\n",
      "Epoch 30/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1154 - accuracy: 0.2715 - precision_8: 0.6396 - recall_8: 0.2333 - auc_8: 0.9453\n",
      "Epoch 31/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1145 - accuracy: 0.2921 - precision_8: 0.6474 - recall_8: 0.2333 - auc_8: 0.9461\n",
      "Epoch 32/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1138 - accuracy: 0.2790 - precision_8: 0.6361 - recall_8: 0.2508 - auc_8: 0.9466\n",
      "Epoch 33/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.1140 - accuracy: 0.3052 - precision_8: 0.6565 - recall_8: 0.2366 - auc_8: 0.9471\n",
      "Epoch 34/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1125 - accuracy: 0.2903 - precision_8: 0.6427 - recall_8: 0.2541 - auc_8: 0.9482\n",
      "Epoch 35/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1127 - accuracy: 0.2996 - precision_8: 0.6781 - recall_8: 0.2607 - auc_8: 0.9480\n",
      "Epoch 36/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.1119 - accuracy: 0.3127 - precision_8: 0.6788 - recall_8: 0.2870 - auc_8: 0.9484\n",
      "Epoch 37/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1109 - accuracy: 0.3184 - precision_8: 0.6805 - recall_8: 0.2870 - auc_8: 0.9497\n",
      "Epoch 38/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1113 - accuracy: 0.2809 - precision_8: 0.6953 - recall_8: 0.2924 - auc_8: 0.9498\n",
      "Epoch 39/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1099 - accuracy: 0.3221 - precision_8: 0.6815 - recall_8: 0.3023 - auc_8: 0.9502\n",
      "Epoch 40/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.1091 - accuracy: 0.3109 - precision_8: 0.6803 - recall_8: 0.3100 - auc_8: 0.9521\n",
      "Epoch 41/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.1093 - accuracy: 0.2996 - precision_8: 0.6768 - recall_8: 0.3165 - auc_8: 0.9512\n",
      "Epoch 42/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1076 - accuracy: 0.3090 - precision_8: 0.6865 - recall_8: 0.3165 - auc_8: 0.9535\n",
      "Epoch 43/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.1088 - accuracy: 0.3296 - precision_8: 0.6804 - recall_8: 0.3264 - auc_8: 0.9516\n",
      "Epoch 44/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.1069 - accuracy: 0.3015 - precision_8: 0.7016 - recall_8: 0.3297 - auc_8: 0.9543\n",
      "Epoch 45/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.1066 - accuracy: 0.3090 - precision_8: 0.7000 - recall_8: 0.3220 - auc_8: 0.9546\n",
      "Epoch 46/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1060 - accuracy: 0.2996 - precision_8: 0.6702 - recall_8: 0.3450 - auc_8: 0.9553\n",
      "Epoch 47/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.1050 - accuracy: 0.3015 - precision_8: 0.6950 - recall_8: 0.3494 - auc_8: 0.9561\n",
      "Epoch 48/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.1055 - accuracy: 0.3333 - precision_8: 0.7042 - recall_8: 0.3494 - auc_8: 0.9553\n",
      "Epoch 49/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.1045 - accuracy: 0.3015 - precision_8: 0.6897 - recall_8: 0.3505 - auc_8: 0.9567\n",
      "Epoch 50/150\n",
      "534/534 [==============================] - 16s 31ms/step - loss: 0.1034 - accuracy: 0.3277 - precision_8: 0.6970 - recall_8: 0.3527 - auc_8: 0.9577\n",
      "Epoch 51/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1037 - accuracy: 0.2790 - precision_8: 0.6762 - recall_8: 0.3614 - auc_8: 0.9576\n",
      "Epoch 52/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1029 - accuracy: 0.3914 - precision_8: 0.7134 - recall_8: 0.3735 - auc_8: 0.9578\n",
      "Epoch 53/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.1030 - accuracy: 0.3146 - precision_8: 0.7065 - recall_8: 0.3560 - auc_8: 0.9587\n",
      "Epoch 54/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1017 - accuracy: 0.3446 - precision_8: 0.7092 - recall_8: 0.3713 - auc_8: 0.9596\n",
      "Epoch 55/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.1018 - accuracy: 0.3240 - precision_8: 0.6901 - recall_8: 0.3658 - auc_8: 0.9587\n",
      "Epoch 56/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.1008 - accuracy: 0.3258 - precision_8: 0.7043 - recall_8: 0.3757 - auc_8: 0.9601\n",
      "Epoch 57/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.1006 - accuracy: 0.3296 - precision_8: 0.7065 - recall_8: 0.3823 - auc_8: 0.9603\n",
      "Epoch 58/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.1010 - accuracy: 0.3390 - precision_8: 0.7101 - recall_8: 0.3757 - auc_8: 0.9593\n",
      "Epoch 59/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0996 - accuracy: 0.3390 - precision_8: 0.7069 - recall_8: 0.3910 - auc_8: 0.9614\n",
      "Epoch 60/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0995 - accuracy: 0.3277 - precision_8: 0.7033 - recall_8: 0.3921 - auc_8: 0.9608\n",
      "Epoch 61/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.1000 - accuracy: 0.3315 - precision_8: 0.7010 - recall_8: 0.3724 - auc_8: 0.9616\n",
      "Epoch 62/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.0989 - accuracy: 0.3408 - precision_8: 0.6902 - recall_8: 0.3855 - auc_8: 0.9628\n",
      "Epoch 63/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0992 - accuracy: 0.3202 - precision_8: 0.7255 - recall_8: 0.3965 - auc_8: 0.9611\n",
      "Epoch 64/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.0985 - accuracy: 0.3427 - precision_8: 0.6987 - recall_8: 0.3987 - auc_8: 0.9624\n",
      "Epoch 65/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0978 - accuracy: 0.3820 - precision_8: 0.6968 - recall_8: 0.4053 - auc_8: 0.9635\n",
      "Epoch 66/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.0969 - accuracy: 0.3502 - precision_8: 0.7170 - recall_8: 0.4162 - auc_8: 0.9639\n",
      "Epoch 67/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0967 - accuracy: 0.3315 - precision_8: 0.7036 - recall_8: 0.4031 - auc_8: 0.9644\n",
      "Epoch 68/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0970 - accuracy: 0.3052 - precision_8: 0.7124 - recall_8: 0.4096 - auc_8: 0.9645\n",
      "Epoch 69/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0968 - accuracy: 0.3727 - precision_8: 0.6961 - recall_8: 0.4140 - auc_8: 0.9639\n",
      "Epoch 70/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.0961 - accuracy: 0.3558 - precision_8: 0.7253 - recall_8: 0.4020 - auc_8: 0.9641\n",
      "Epoch 71/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0956 - accuracy: 0.3539 - precision_8: 0.7090 - recall_8: 0.4217 - auc_8: 0.9653\n",
      "Epoch 72/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0954 - accuracy: 0.3521 - precision_8: 0.7140 - recall_8: 0.4294 - auc_8: 0.9652\n",
      "Epoch 73/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0941 - accuracy: 0.3521 - precision_8: 0.7291 - recall_8: 0.4304 - auc_8: 0.9663\n",
      "Epoch 74/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0948 - accuracy: 0.3446 - precision_8: 0.7089 - recall_8: 0.4107 - auc_8: 0.9655\n",
      "Epoch 75/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0942 - accuracy: 0.3858 - precision_8: 0.7398 - recall_8: 0.4359 - auc_8: 0.9664\n",
      "Epoch 76/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0943 - accuracy: 0.3427 - precision_8: 0.7422 - recall_8: 0.4195 - auc_8: 0.9657\n",
      "Epoch 77/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.0936 - accuracy: 0.3090 - precision_8: 0.7111 - recall_8: 0.4502 - auc_8: 0.9667\n",
      "Epoch 78/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0938 - accuracy: 0.3390 - precision_8: 0.7298 - recall_8: 0.4348 - auc_8: 0.9662\n",
      "Epoch 79/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0933 - accuracy: 0.3408 - precision_8: 0.7224 - recall_8: 0.4589 - auc_8: 0.9669\n",
      "Epoch 80/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0917 - accuracy: 0.3764 - precision_8: 0.7308 - recall_8: 0.4370 - auc_8: 0.9683\n",
      "Epoch 81/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0918 - accuracy: 0.3933 - precision_8: 0.7316 - recall_8: 0.4567 - auc_8: 0.9676\n",
      "Epoch 82/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.0920 - accuracy: 0.3801 - precision_8: 0.7230 - recall_8: 0.4545 - auc_8: 0.9675\n",
      "Epoch 83/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0912 - accuracy: 0.4082 - precision_8: 0.7346 - recall_8: 0.4578 - auc_8: 0.9689\n",
      "Epoch 84/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0914 - accuracy: 0.3670 - precision_8: 0.7108 - recall_8: 0.4524 - auc_8: 0.9691\n",
      "Epoch 85/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0910 - accuracy: 0.3951 - precision_8: 0.7279 - recall_8: 0.4513 - auc_8: 0.9688\n",
      "Epoch 86/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0907 - accuracy: 0.3708 - precision_8: 0.7357 - recall_8: 0.4513 - auc_8: 0.9687\n",
      "Epoch 87/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0906 - accuracy: 0.3820 - precision_8: 0.7464 - recall_8: 0.4545 - auc_8: 0.9690\n",
      "Epoch 88/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0898 - accuracy: 0.3427 - precision_8: 0.7126 - recall_8: 0.4754 - auc_8: 0.9701\n",
      "Epoch 89/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0899 - accuracy: 0.3670 - precision_8: 0.7211 - recall_8: 0.4644 - auc_8: 0.9695\n",
      "Epoch 90/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0900 - accuracy: 0.4045 - precision_8: 0.7244 - recall_8: 0.4578 - auc_8: 0.9696\n",
      "Epoch 91/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0883 - accuracy: 0.3689 - precision_8: 0.7390 - recall_8: 0.4775 - auc_8: 0.9706\n",
      "Epoch 92/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0885 - accuracy: 0.3933 - precision_8: 0.7407 - recall_8: 0.4786 - auc_8: 0.9708\n",
      "Epoch 93/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0881 - accuracy: 0.3596 - precision_8: 0.7470 - recall_8: 0.4786 - auc_8: 0.9711\n",
      "Epoch 94/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0878 - accuracy: 0.3727 - precision_8: 0.7411 - recall_8: 0.4797 - auc_8: 0.9712\n",
      "Epoch 95/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0887 - accuracy: 0.4026 - precision_8: 0.7344 - recall_8: 0.4633 - auc_8: 0.9711\n",
      "Epoch 96/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0874 - accuracy: 0.3820 - precision_8: 0.7417 - recall_8: 0.4874 - auc_8: 0.9722\n",
      "Epoch 97/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0870 - accuracy: 0.3783 - precision_8: 0.7438 - recall_8: 0.4929 - auc_8: 0.9719\n",
      "Epoch 98/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0869 - accuracy: 0.3876 - precision_8: 0.7372 - recall_8: 0.4885 - auc_8: 0.9718\n",
      "Epoch 99/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0858 - accuracy: 0.3951 - precision_8: 0.7352 - recall_8: 0.4896 - auc_8: 0.9727\n",
      "Epoch 100/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0872 - accuracy: 0.3633 - precision_8: 0.7303 - recall_8: 0.4775 - auc_8: 0.9720\n",
      "Epoch 101/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0870 - accuracy: 0.3820 - precision_8: 0.7434 - recall_8: 0.4918 - auc_8: 0.9715\n",
      "Epoch 102/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0855 - accuracy: 0.3839 - precision_8: 0.7472 - recall_8: 0.5082 - auc_8: 0.9728\n",
      "Epoch 103/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.0853 - accuracy: 0.3876 - precision_8: 0.7504 - recall_8: 0.5071 - auc_8: 0.9733\n",
      "Epoch 104/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0842 - accuracy: 0.3951 - precision_8: 0.7508 - recall_8: 0.5049 - auc_8: 0.9735\n",
      "Epoch 105/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0861 - accuracy: 0.4139 - precision_8: 0.7387 - recall_8: 0.4830 - auc_8: 0.9725\n",
      "Epoch 106/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0846 - accuracy: 0.4157 - precision_8: 0.7447 - recall_8: 0.4984 - auc_8: 0.9731\n",
      "Epoch 107/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0835 - accuracy: 0.3970 - precision_8: 0.7492 - recall_8: 0.5170 - auc_8: 0.9738\n",
      "Epoch 108/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0838 - accuracy: 0.4082 - precision_8: 0.7579 - recall_8: 0.5246 - auc_8: 0.9739\n",
      "Epoch 109/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0840 - accuracy: 0.4157 - precision_8: 0.7598 - recall_8: 0.5093 - auc_8: 0.9738\n",
      "Epoch 110/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0841 - accuracy: 0.3764 - precision_8: 0.7557 - recall_8: 0.5115 - auc_8: 0.9743\n",
      "Epoch 111/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0826 - accuracy: 0.4176 - precision_8: 0.7579 - recall_8: 0.5279 - auc_8: 0.9754\n",
      "Epoch 112/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0831 - accuracy: 0.3839 - precision_8: 0.7563 - recall_8: 0.5301 - auc_8: 0.9744\n",
      "Epoch 113/150\n",
      "534/534 [==============================] - 15s 29ms/step - loss: 0.0820 - accuracy: 0.4251 - precision_8: 0.7504 - recall_8: 0.5137 - auc_8: 0.9750\n",
      "Epoch 114/150\n",
      "534/534 [==============================] - 17s 31ms/step - loss: 0.0827 - accuracy: 0.3670 - precision_8: 0.7360 - recall_8: 0.5192 - auc_8: 0.9749\n",
      "Epoch 115/150\n",
      "534/534 [==============================] - 21s 40ms/step - loss: 0.0819 - accuracy: 0.4064 - precision_8: 0.7639 - recall_8: 0.5422 - auc_8: 0.9753\n",
      "Epoch 116/150\n",
      "534/534 [==============================] - 21s 40ms/step - loss: 0.0817 - accuracy: 0.3708 - precision_8: 0.7480 - recall_8: 0.5005 - auc_8: 0.9762\n",
      "Epoch 117/150\n",
      "534/534 [==============================] - 21s 40ms/step - loss: 0.0816 - accuracy: 0.3783 - precision_8: 0.7621 - recall_8: 0.5367 - auc_8: 0.9760\n",
      "Epoch 118/150\n",
      "534/534 [==============================] - 21s 40ms/step - loss: 0.0821 - accuracy: 0.4101 - precision_8: 0.7571 - recall_8: 0.5290 - auc_8: 0.9758\n",
      "Epoch 119/150\n",
      "534/534 [==============================] - 15s 28ms/step - loss: 0.0813 - accuracy: 0.4176 - precision_8: 0.7655 - recall_8: 0.5148 - auc_8: 0.9761\n",
      "Epoch 120/150\n",
      "534/534 [==============================] - 14s 26ms/step - loss: 0.0807 - accuracy: 0.4026 - precision_8: 0.7701 - recall_8: 0.5246 - auc_8: 0.9758\n",
      "Epoch 121/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0811 - accuracy: 0.3839 - precision_8: 0.7508 - recall_8: 0.5246 - auc_8: 0.9762\n",
      "Epoch 122/150\n",
      "534/534 [==============================] - 17s 31ms/step - loss: 0.0798 - accuracy: 0.4251 - precision_8: 0.7559 - recall_8: 0.5290 - auc_8: 0.9769\n",
      "Epoch 123/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0803 - accuracy: 0.4045 - precision_8: 0.7744 - recall_8: 0.5378 - auc_8: 0.9765\n",
      "Epoch 124/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0794 - accuracy: 0.4176 - precision_8: 0.7641 - recall_8: 0.5356 - auc_8: 0.9776\n",
      "Epoch 125/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0812 - accuracy: 0.3933 - precision_8: 0.7388 - recall_8: 0.5235 - auc_8: 0.9756\n",
      "Epoch 126/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0793 - accuracy: 0.4195 - precision_8: 0.7484 - recall_8: 0.5214 - auc_8: 0.9778\n",
      "Epoch 127/150\n",
      "534/534 [==============================] - 16s 29ms/step - loss: 0.0798 - accuracy: 0.3970 - precision_8: 0.7713 - recall_8: 0.5356 - auc_8: 0.9771\n",
      "Epoch 128/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0796 - accuracy: 0.4120 - precision_8: 0.7508 - recall_8: 0.5279 - auc_8: 0.9774\n",
      "Epoch 129/150\n",
      "534/534 [==============================] - 16s 31ms/step - loss: 0.0774 - accuracy: 0.3689 - precision_8: 0.7631 - recall_8: 0.5575 - auc_8: 0.9787\n",
      "Epoch 130/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0776 - accuracy: 0.4195 - precision_8: 0.7693 - recall_8: 0.5444 - auc_8: 0.9783\n",
      "Epoch 131/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0784 - accuracy: 0.4270 - precision_8: 0.7617 - recall_8: 0.5531 - auc_8: 0.9781\n",
      "Epoch 132/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0769 - accuracy: 0.3689 - precision_8: 0.7622 - recall_8: 0.5652 - auc_8: 0.9793\n",
      "Epoch 133/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0784 - accuracy: 0.4026 - precision_8: 0.7771 - recall_8: 0.5422 - auc_8: 0.9773\n",
      "Epoch 134/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0782 - accuracy: 0.3876 - precision_8: 0.7523 - recall_8: 0.5487 - auc_8: 0.9782\n",
      "Epoch 135/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0773 - accuracy: 0.4026 - precision_8: 0.7723 - recall_8: 0.5498 - auc_8: 0.9784\n",
      "Epoch 136/150\n",
      "534/534 [==============================] - 16s 31ms/step - loss: 0.0762 - accuracy: 0.4101 - precision_8: 0.7857 - recall_8: 0.5542 - auc_8: 0.9791\n",
      "Epoch 137/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0760 - accuracy: 0.4513 - precision_8: 0.7623 - recall_8: 0.5619 - auc_8: 0.9798\n",
      "Epoch 138/150\n",
      "534/534 [==============================] - 17s 31ms/step - loss: 0.0783 - accuracy: 0.3727 - precision_8: 0.7695 - recall_8: 0.5520 - auc_8: 0.9782\n",
      "Epoch 139/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0768 - accuracy: 0.4176 - precision_8: 0.7673 - recall_8: 0.5706 - auc_8: 0.9787\n",
      "Epoch 140/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0758 - accuracy: 0.4007 - precision_8: 0.7831 - recall_8: 0.5575 - auc_8: 0.9790\n",
      "Epoch 141/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0758 - accuracy: 0.4157 - precision_8: 0.7850 - recall_8: 0.5400 - auc_8: 0.9793\n",
      "Epoch 142/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0775 - accuracy: 0.3951 - precision_8: 0.7624 - recall_8: 0.5553 - auc_8: 0.9786\n",
      "Epoch 143/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0760 - accuracy: 0.4195 - precision_8: 0.7798 - recall_8: 0.5739 - auc_8: 0.9796\n",
      "Epoch 144/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0772 - accuracy: 0.4007 - precision_8: 0.7675 - recall_8: 0.5531 - auc_8: 0.9782\n",
      "Epoch 145/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0755 - accuracy: 0.4064 - precision_8: 0.7689 - recall_8: 0.5575 - auc_8: 0.9791\n",
      "Epoch 146/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0760 - accuracy: 0.3764 - precision_8: 0.7882 - recall_8: 0.5706 - auc_8: 0.9794\n",
      "Epoch 147/150\n",
      "534/534 [==============================] - 16s 31ms/step - loss: 0.0758 - accuracy: 0.4176 - precision_8: 0.7813 - recall_8: 0.5674 - auc_8: 0.9792\n",
      "Epoch 148/150\n",
      "534/534 [==============================] - 16s 30ms/step - loss: 0.0750 - accuracy: 0.3933 - precision_8: 0.7917 - recall_8: 0.5455 - auc_8: 0.9802\n",
      "Epoch 149/150\n",
      "534/534 [==============================] - 16s 31ms/step - loss: 0.0752 - accuracy: 0.3783 - precision_8: 0.7663 - recall_8: 0.5674 - auc_8: 0.9796\n",
      "Epoch 150/150\n",
      "534/534 [==============================] - 17s 32ms/step - loss: 0.0747 - accuracy: 0.3558 - precision_8: 0.7820 - recall_8: 0.5619 - auc_8: 0.9804\n"
     ]
    }
   ],
   "source": [
    "history=model.fit((field_id,cand_pos,neighbours,neighbour_positions),y_train,epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ece82371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "93 97\n"
     ]
    }
   ],
   "source": [
    "key='./json_keys'\n",
    "csv_dataset='./tesseract_invoice_csv_dataset'\n",
    "invoices=os.listdir(csv_dataset)\n",
    "total_check=0\n",
    "correct=0\n",
    "for inv_csv in range(626,723): #these are cab aggregator service invoice from 626 to 723\n",
    "   total_check+=1\n",
    "   file_name=str(inv_csv)\n",
    "   file_name=file_name.zfill(3) \n",
    "   data=json.load(open(key+'/'+file_name+'.json','r'))\n",
    "   if 'amount' in data:\n",
    "       total=str(data['amount'])\n",
    "   else:\n",
    "       total=str(data['total'])\n",
    "   if total=='':\n",
    "      continue\n",
    "   total=preprocess(total)\n",
    "   df=pd.read_csv(f'{csv_dataset}/{file_name}.csv')\n",
    "   height=max(df['top'].max(),df['height'].max())\n",
    "   width=max(df['left'].max(),df['width'].max())\n",
    "   candidates=generate(df,10,'-1',height,width)\n",
    "   if len(candidates)==0:\n",
    "      continue\n",
    "   candidates.reset_index(inplace=True)\n",
    "   cand_pos=tf.convert_to_tensor(list(candidates['candidate_position']))\n",
    "   neighbours=tf.convert_to_tensor(list(candidates['neighbour_id']))\n",
    "   neighbour_positions=tf.convert_to_tensor(list(candidates['neighbour_relative_position']))\n",
    "   field_id=tf.convert_to_tensor(list(candidates['field_id']))\n",
    "   data=model.predict((field_id,cand_pos,neighbours,neighbour_positions))\n",
    "   amount_predicted=''\n",
    "   score=0\n",
    "   for i in range(len(data)):\n",
    "      if data[i]>score:\n",
    "          amount_predicted=candidates.at[i,'text']\n",
    "          score=data[i]\n",
    "   if float(amount_predicted)==float(total):\n",
    "      correct+=1 \n",
    "print(correct,total_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3d0914d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panwar2001/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('amount_large.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad6d286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
